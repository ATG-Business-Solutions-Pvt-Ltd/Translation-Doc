# -*- coding: utf-8 -*-
"""M-BART-From-File-Multi-lingualTranslation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R-HGsNgk6p2jiIo-ebUOS1GQEiY5j9St
"""
from transformers import MBartForConditionalGeneration, MBart50Tokenizer
import streamlit as st

import fpdf
from PyPDF2 import PdfFileReader
from PyPDF2 import PdfReader

model_name = "facebook/mbart-large-50-many-to-many-mmt"
model = MBartForConditionalGeneration.from_pretrained(model_name)
tokenizer = MBart50Tokenizer.from_pretrained(model_name)

language=['Czech','German','French','Estonian','Spanish','Finnish']

st.title('Multiple Languages to English Translator')
#text = st.text_area("Upload Text file:", value='', height=None, max_chars=None, key=None)
source_language = st.selectbox("Select source language", language)

import fpdf
pdf = fpdf.FPDF(format='letter')
pdf.add_font('Arial', '', '/content/arial.ttf', uni=True) #path of the font file is set to avoid the error generated by U+2019=','
pdf.set_font("Arial", size=12)
pdf.add_page()

import streamlit as st
from io import StringIO

File = st.file_uploader("Choose a file")
if File is not None:
  # To convert to a string based IO:
    #FileContent = StringIO(File.getvalue().decode("utf-8"))
    #st.write(FileContent)
    FileContent = File.read()
    st.write("filename:", File.name)

if st.button('Translate to English'):
  reader=PdfReader(File)
  num_pages=len(reader.pages)
  for p in range(num_pages):
    page=reader.pages[p]
    FileContent=page.extract_text()
    text = FileContent.encode('latin-1', 'replace').decode('latin-1')
    #translate Czech to English
    if source_language=='Czech':
        tokenizer.src_lang = "cs_CZ"
        encoded_cs = tokenizer(text, return_tensors="pt")
        generated_tokens = model.generate(**encoded_cs,forced_bos_token_id=tokenizer.lang_code_to_id["en_XX"])
        out=tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
        st.write('', str(out).strip('][\''))
    #translate French to English
    if source_language=='French':
        tokenizer.src_lang = "fr_XX"
        encoded_fr = tokenizer(text, return_tensors="pt")
        generated_tokens = model.generate(**encoded_fr,forced_bos_token_id=tokenizer.lang_code_to_id["en_XX"])
        out=tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
        st.write('', str(out).strip('][\''))
    #translate Estonian to English
    if source_language=='Estonian':
        tokenizer.src_lang = "et_EE"
        encoded_et = tokenizer(text, return_tensors="pt")
        generated_tokens = model.generate(**encoded_et,forced_bos_token_id=tokenizer.lang_code_to_id["en_XX"])
        out=tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
        st.write('', str(out).strip('][\''))
    #translate German to English
    if source_language=='German':
        tokenizer.src_lang = "de_DE"
        encoded_de = tokenizer(text, return_tensors="pt")
        generated_tokens = model.generate(**encoded_de,forced_bos_token_id=tokenizer.lang_code_to_id["en_XX"])
        out=tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
        st.write('', str(out).strip('][\''))
    #translate Spanish to English
    if source_language=='Spanish':
        tokenizer.src_lang = "es_XX"
        encoded_de = tokenizer(text, return_tensors="pt")
        generated_tokens = model.generate(**encoded_de,forced_bos_token_id=tokenizer.lang_code_to_id["en_XX"])
        out=tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
        st.write('', str(out).strip('][\''))
    #translate Finnish to English
    if source_language=='Finnish':
        tokenizer.src_lang = "fi_FI"
        encoded_de = tokenizer(text, return_tensors="pt")
        generated_tokens = model.generate(**encoded_de,forced_bos_token_id=tokenizer.lang_code_to_id["en_XX"])
        out=tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
        st.write('', str(out).strip('][\''))
  pdf.output("Translated-T.pdf")
else: pass

from google.colab import drive

